{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNl7Mr5ixwuc0dQhq2OVAwU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["1.What is the role of filters and feature maps in Convolutional Neural\n","Network (CNN)?\n","- In a Convolutional Neural Network (CNN), filters (kernels) and feature maps are core components that enable the network to automatically learn and extract useful patterns from input data such as images.\n","- A filter is a small matrix of learnable weights (e.g., 3×3, 5×5) that slides over the input image or feature map.\n","- A feature map is the output produced when a filter is convolved with the input.\n","\n","2.Explain the concepts of padding and stride in CNNs(Convolutional Neural\n","Network). How do they affect the output dimensions of feature maps?\n","- In Convolutional Neural Networks (CNNs), padding and stride are important hyperparameters that control how convolution is applied and how the output size (feature map dimensions) changes.\n","- Padding means adding extra pixels (usually zeros) around the border of the input image before applying the filter.\n","- Stride is the number of pixels the filter moves at each step during convolution.\n","\n","3.Define receptive field in the context of CNNs. Why is it important for deep\n","architectures?\n","- In the context of CNNs, the receptive field of a neuron (or unit) is the region of the input image that influences the activation of that neuron.\n","- Importance of Receptive Field in Deep Architectures\n","   - Captures Local and Global Features\n","   - Hierarchical Feature Learning\n","   - Context Awareness\n","\n","4.Discuss how filter size and stride influence the number of parameters in a\n","CNN.\n","- In a Convolutional Neural Network (CNN), the number of parameters mainly depends on the filter (kernel) size, number of filters, and number of input channels.\n","- Stride affects the output feature map size and computation, but it has a limited or no direct effect on the number of parameters.\n","\n","5.Discuss how filter size and stride influence the number of parameters in a\n","CNN.\n","- LeNet is one of the earliest CNN architectures, primarily designed for handwritten digit recognition. It is a shallow network with a small number of convolutional and fully connected layers. LeNet uses relatively large convolution filters and simple activation functions such as sigmoid or tanh. Due to its limited depth and computational capacity, LeNet performs well on simple, low-resolution datasets but is not suitable for complex image recognition tasks.\n","- AlexNet marked a major breakthrough in deep learning by demonstrating the power of deeper CNNs on large-scale datasets. It significantly increased the depth of the network and introduced important innovations such as ReLU activation functions, max pooling, and dropout for regularization. AlexNet uses a combination of large and small convolution filters to capture both coarse and fine features. Its success on the ImageNet challenge proved that deep CNNs can achieve high performance on complex image classification problems.\n","- VGG further advanced CNN design by emphasizing depth and architectural simplicity. Instead of using large convolution filters, VGG consistently employs small 3×3 filters stacked across many layers. This design increases the effective receptive field while keeping the architecture uniform. VGG networks achieve very high accuracy due to their deep structure and strong feature extraction capability, but they also require large amounts of memory and computational resources.\n","\n","6.Using keras, build and train a simple CNN model on the MNIST dataset\n","from scratch. Include code for module creation, compilation, training, and evaluation.\n"],"metadata":{"id":"wSmGcnayIRdK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCnO92ygIMNY","outputId":"c4b41543-94b2-4895-942e-3d1ed50242ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 56ms/step - accuracy: 0.8879 - loss: 0.3703 - val_accuracy: 0.9838 - val_loss: 0.0604\n","Epoch 2/5\n","\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 62ms/step - accuracy: 0.9821 - loss: 0.0574 - val_accuracy: 0.9867 - val_loss: 0.0463\n","Epoch 3/5\n","\u001b[1m316/844\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - accuracy: 0.9893 - loss: 0.0324"]}],"source":["# Step 1: Import required libraries\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow.keras.utils import to_categorical\n","\n","# Step 2: Load MNIST dataset\n","(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n","\n","# Step 3: Preprocess the data\n","# Reshape to add channel dimension\n","x_train = x_train.reshape((60000, 28, 28, 1))\n","x_test = x_test.reshape((10000, 28, 28, 1))\n","\n","# Normalize pixel values\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","# Convert labels to one-hot encoding\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# Step 4: Build the CNN model\n","model = models.Sequential()\n","\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","                        input_shape=(28, 28, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# Step 5: Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Step 6: Train the model\n","history = model.fit(x_train, y_train,\n","                    epochs=5,\n","                    batch_size=64,\n","                    validation_split=0.1)\n","\n","# Step 7: Evaluate the model\n","test_loss, test_accuracy = model.evaluate(x_test, y_test)\n","\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_accuracy)\n"]},{"cell_type":"markdown","source":["7.Load and preprocess the CIFAR-10 dataset using Keras, and create a\n","CNN model to classify RGB images. Show your preprocessing and architecture."],"metadata":{"id":"C0pzwhsALx3J"}},{"cell_type":"code","source":["# Step 1: Import required libraries\n","import tensorflow as tf\n","from tensorflow.keras import datasets, layers, models\n","from tensorflow.keras.utils import to_categorical\n","\n","# Step 2: Load CIFAR-10 dataset\n","(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n","\n","# Step 3: Preprocess the data\n","\n","# Normalize pixel values (0–255 -> 0–1)\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# One-hot encode class labels\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Print shapes\n","print(\"Training data shape:\", x_train.shape)\n","print(\"Testing data shape:\", x_test.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN9tFi-DLzGW","executionInfo":{"status":"ok","timestamp":1767533348154,"user_tz":-330,"elapsed":34213,"user":{"displayName":"Tanmay Ghule","userId":"02288771655695874608"}},"outputId":"913c6ebf-00d7-4c10-a3eb-4d34bd9c2b9c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 0us/step\n","Training data shape: (50000, 32, 32, 3)\n","Testing data shape: (10000, 32, 32, 3)\n"]}]},{"cell_type":"markdown","source":["8.Using PyTorch, write a script to define and train a CNN on the MNIST\n","dataset. Include model definition, data loaders, training loop, and accuracy evaluation."],"metadata":{"id":"aCh4VYQuL8Z6"}},{"cell_type":"code","source":["# Step 1: Import required libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Step 2: Define device (CPU / GPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# Step 3: Define data transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),                 # Convert image to tensor\n","    transforms.Normalize((0.1307,), (0.3081,))  # Normalize MNIST data\n","])\n","\n","# Step 4: Load MNIST dataset\n","train_dataset = datasets.MNIST(\n","    root='./data',\n","    train=True,\n","    download=True,\n","    transform=transform\n",")\n","\n","test_dataset = datasets.MNIST(\n","    root='./data',\n","    train=False,\n","    download=True,\n","    transform=transform\n",")\n","\n","# Step 5: Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","\n","# Step 6: Define the CNN model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n","        self.pool = nn.MaxPool2d(2)\n","        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.conv1(x))\n","        x = self.pool(torch.relu(self.conv2(x)))\n","        x = x.view(x.size(0), -1)   # Flatten\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x\n","\n","# Step 7: Initialize model, loss function, and optimizer\n","model = CNN().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Step 8: Training loop\n","epochs = 5\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()          # Clear gradients\n","        outputs = model(images)        # Forward pass\n","        loss = criterion(outputs, labels)\n","        loss.backward()                # Backpropagation\n","        optimizer.step()               # Update weights\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n","\n","# Step 9: Model evaluation (accuracy)\n","model.eval()\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f\"Test Accuracy: {accuracy:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FpMP9vJfL7kT","executionInfo":{"status":"ok","timestamp":1767533475851,"user_tz":-330,"elapsed":104533,"user":{"displayName":"Tanmay Ghule","userId":"02288771655695874608"}},"outputId":"eb5bfa03-ac61-4025-acba-e86333e13e13"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:02<00:00, 4.57MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 131kB/s]\n","100%|██████████| 1.65M/1.65M [00:01<00:00, 1.23MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 8.88MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Loss: 0.1177\n","Epoch [2/5], Loss: 0.0375\n","Epoch [3/5], Loss: 0.0235\n","Epoch [4/5], Loss: 0.0160\n","Epoch [5/5], Loss: 0.0111\n","Test Accuracy: 99.14%\n"]}]},{"cell_type":"markdown","source":["9.Given a custom image dataset stored in a local directory, write code using\n","Keras ImageDataGenerator to preprocess and train a CNN model."],"metadata":{"id":"fQFYDQwGMNAe"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255,        # Normalize pixel values\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","val_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255\n",")\n","train_generator = train_datagen.flow_from_directory(\n","    directory='dataset/train',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","validation_generator = val_datagen.flow_from_directory(\n","    directory='dataset/validation',\n","    target_size=(128, 128),\n","    batch_size=32,\n","    class_mode='categorical'\n",")\n","\n","model = models.Sequential()\n","\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","                        input_shape=(128, 128, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dense(train_generator.num_classes, activation='softmax'))\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","model.summary()\n","history = model.fit(\n","    train_generator,\n","    epochs=10,\n","    validation_data=validation_generator\n",")\n","\n"],"metadata":{"id":"3WgcL5etMlht"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10.You are working on a web application for a medical imaging startup. Your\n","task is to build and deploy a CNN model that classifies chest X-ray images into “Normal”\n","and “Pneumonia” categories. Describe your end-to-end approach–from data preparation\n","and model training to deploying the model as a web app using Streamlit.\n","\n","- Problem Understanding\n","\n","The goal is to build a binary image classification system that takes a chest X-ray image as input and predicts whether it is Normal or shows signs of Pneumonia. The solution must be accurate, efficient, and deployable as a web application.\n","\n","- Data Preparation\n","Dataset Collection\n","\n","Use a labeled chest X-ray dataset (e.g., public medical datasets).\n","\n","Images are categorized into two folde\n","- Model Selection and Architecture\n","- Model Training\n","- Model Evaluation"],"metadata":{"id":"ydmHOK_iNFvE"}},{"cell_type":"code","source":["import streamlit as st\n","import tensorflow as tf\n","from PIL import Image\n","import numpy as np\n","\n","# Load trained model\n","model = tf.keras.models.load_model(\"pneumonia_cnn_model.h5\")\n","\n","st.title(\"Chest X-ray Pneumonia Detection\")\n","\n","uploaded_file = st.file_uploader(\"Upload Chest X-ray Image\", type=[\"jpg\", \"png\", \"jpeg\"])\n","\n","if uploaded_file is not None:\n","    image = Image.open(uploaded_file).convert(\"RGB\")\n","    st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n","\n","    # Preprocess image\n","    image = image.resize((224, 224))\n","    img_array = np.array(image) / 255.0\n","    img_array = np.expand_dims(img_array, axis=0)\n","\n","    # Prediction\n","    prediction = model.predict(img_array)[0][0]\n","\n","    if prediction > 0.5:\n","        st.error(f\"Pneumonia Detected (Confidence: {prediction:.2f})\")\n","    else:\n","        st.success(f\"Normal (Confidence: {1 - prediction:.2f})\")\n"],"metadata":{"id":"QLTq-v4iNJax"},"execution_count":null,"outputs":[]}]}